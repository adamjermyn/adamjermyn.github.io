<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Safety on Adam Jermyn</title>
    <link>https://adamjermyn.com/tags/ai-safety/</link>
    <description>Recent content in AI Safety on Adam Jermyn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 14 Mar 2022 14:27:25 -0400</lastBuildDate><atom:link href="https://adamjermyn.com/tags/ai-safety/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI risk in a few words</title>
      <link>https://adamjermyn.com/posts/ai_risk_few_words/</link>
      <pubDate>Mon, 14 Mar 2022 14:27:25 -0400</pubDate>
      
      <guid>https://adamjermyn.com/posts/ai_risk_few_words/</guid>
      <description>AI safety is a weird area, and in trying to explain it to friends I realized that I don&amp;rsquo;t have a simple explanation of what the (existential) risks are and why I think they&amp;rsquo;re important.
Word limits force simplicity, so here are some attempts to explain AI risk in different numbers of words.
150 words  Do you value the same things as your great grandfather? What we value changes from generation to generation.</description>
    </item>
    
  </channel>
</rss>
