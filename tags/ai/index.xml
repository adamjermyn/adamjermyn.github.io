<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Adam Jermyn</title>
    <link>https://adamjermyn.com/tags/ai/</link>
    <description>Recent content in AI on Adam Jermyn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 12 Apr 2022 17:17:54 -0400</lastBuildDate><atom:link href="https://adamjermyn.com/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Working Notes - Learning PyTorch - Day 2</title>
      <link>https://adamjermyn.com/posts/ml_2/</link>
      <pubDate>Tue, 12 Apr 2022 17:17:54 -0400</pubDate>
      
      <guid>https://adamjermyn.com/posts/ml_2/</guid>
      <description>Summary  Adding convolutional layers is pretty straightforward, but there are some indexing subtleties to watch. Pooling layers can really improve performance. With two pooling layers, I found an example of a too-high learning rate making the model get stuck with poor performance. The more pooling layers I used the faster the model took a training step (because the dense linear layer was smaller). The more pooling layers I used, the more important the number of channels in the convolutional/pooling layers became.</description>
    </item>
    
    <item>
      <title>Working Notes - Learning PyTorch - Day 1</title>
      <link>https://adamjermyn.com/posts/ml_1/</link>
      <pubDate>Mon, 11 Apr 2022 17:06:39 -0400</pubDate>
      
      <guid>https://adamjermyn.com/posts/ml_1/</guid>
      <description>Summary  Covered boilerplate for getting started, tensors, gradients. Poked in some detail at how gradients work. Played with linear regression, nonlinear regression, both with gradient descent. Built an MNIST classifier following a PyTorch tutorial. Experimented with the shape and size of the NN. Got PyTorch running on a machine with a GPU.  Boilerplate Import:
import torch Need to use a special float type for the elements of tensors, and need to know which device the compute graph will run on:</description>
    </item>
    
  </channel>
</rss>
